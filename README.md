# notes_of_GraphRAG_with_local_LLM
This is an repo noting local deployment of GraphRAG inferencing with locally deployed LLMs.
//TODOs
//Basic hardware/software specifications of this setups
Steps:
Notes to be paid attention to:
Explainations about the steps:
Youtube/Bilibili Link to the video:
Next/follow-up to the experiments
References

中文版内容

NOTES to MYSELF:

This should be a more comprehensive and further going projects than simply making it working, 3 months of active moding and managing needed.
